<h1 align = "center">《知识工程》实体标注任务实验报告</h1>
<p align = "center">07032001 苗沂坤 1120201064</p>

## 1. 实验目的
完成自然语言处理（nlp）中经典的命名实体识别任务。需要对文段语句中的机构名、地名、人名进行预测并标注。其中相关语料已经经过分词、标注词性。

## 2. 系统环境及代码说明
* python解释器版本
`Python 3.9.7 [MSC v.1916 64 bit (AMD64)] on win32`
* 使用的第三方库
  1. `pytorch == 1.11.0`，用于提供训练所需要的`tensor`容器以及自动求导功能。
  2. `matplotlib == 3.4.3`，用于作图分析模型在训练过程中的变化。
* 文件架构以及作用说明
  
## 3. 实现方法
### 3.1 预处理方法
1. 扫描语料文件，以空格作为分隔符，提取出每个词语的**内容**以及**词性**（其中机构名为nt，地名为ns，人名为nr，姓为nrf，名为nrg），放于`list()`中形成二元组。并将所有的二元组放置于列表`word`中。
2. 按照词性，对于所有列表`word`中的元素添加标记，构成列表`data`。列表`data`中的元素前两维和列表`word`相同，第三、四、五维分别代表了**机构名**、**地名**、**人名**的标记。标记有$O,B,I$三种，分别用整数$0,1,2$代替。其中，$O$代表这个词不属于相应类型，$B$表示这个词为相应类型短语的开头（或当短语只包含一个词的时候），$I$表示这个词为相应短语非开头部分。
3. 需要对于每个词提取出其前一个以及后一个词语，采用`one-hot`编码方式形成一个一维向量。这个一维向量对应了机构名、地名、人名三个输出值。构建`one-hot`编码需要一个字典`dict`来将每一个词语映射到一个整数上。这里我们提取了最经常出现的`650`个词，即字典大小`dict_size = 650`，将其中每个词映射到`[1,650]`中的整数上。（未出现在字典里的词将映射为$0$）
4. 经过前三步的操作，对于每个词我们得到了一个大小为$3*651$的向量和一个大小为$3$的向量，分别作为模型的输入值和输出值。我们将这两个向量转化为`torch.tenser`类型的变量，分别放入列表`x_tlist`和`y_tlist`中以便后续训练。

### 3.2 通过广义线性模型GLM构建Softmax模型
不妨设输入和输出分别为$X,Y$，其中$X$为上文提到的大小为$3*651$的向量，$Y$为一个在$\left \{ 0, 1, 2 \right \}$中取值的整数（通过构建三个这样的模型来分别预测机构名、地名、人名的标签）。
$$ P(Y=0|X)=\phi_0,P(Y=1|X)=\phi_1,P(Y=2|X)=\phi_2$$
由`Softmax`模型相关理论可以有如下定义：
$$\phi_0=\frac{e^{\theta_0^TX}}{\Sigma_{i=0}^{2} e^{\theta_i^TX}},\phi_1=\frac{e^{\theta_1^TX}}{\Sigma_{i=0}^{2} e^{\theta_i^TX}},
\phi_2=\frac{e^{\theta_2^TX}}{\Sigma_{i=0}^{2} e^{\theta_i^TX}}(其中\theta_2=0)$$

### 3.3 通过梯度下降进行参数优化
#### 3.3.1 自动求导
#### 3.3.2 手动求导

## 4.运行结果及分析

## 5.总结

